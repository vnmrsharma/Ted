# ğŸ¯ Advanced Emotion Detection System

This folder contains a complete, state-of-the-art emotion detection system using a fine-tuned EfficientNet-B2 neural network with advanced training techniques.

## ğŸ“ File Structure

```
trained-sentiment/
â”œâ”€â”€ training.py                    # Advanced training pipeline (MAIN TRAINING)
â”œâ”€â”€ test.py                       # Comprehensive model testing
â”œâ”€â”€ main.py                       # Real-time webcam detection (MAIN RUNTIME)
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # This documentation
```

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Train the Model
```bash
python3 training.py --epochs 100 --batch_size 32
```

### 3. Test the Model
```bash
python3 test.py --max_samples 100
```

### 4. Run Real-time Detection
```bash
python3 main.py
```

## ğŸ¯ System Features

### **Advanced Training (`training.py`)**
- **Model**: EfficientNet-B2 backbone (better than B0)
- **Architecture**: Multi-layer classifier with BatchNorm and Dropout
- **Augmentation**: Advanced Albumentations pipeline
- **Optimizer**: AdamW with weight decay
- **Scheduler**: OneCycleLR with cosine annealing
- **Loss**: CrossEntropyLoss with label smoothing
- **Performance**: Expected 75%+ validation accuracy

### **Comprehensive Testing (`test.py`)**
- **Validation Dataset**: Full Kaggle FER2013 validation set
- **Metrics**: Accuracy, precision, recall, F1-score
- **Visualization**: Confusion matrix, confidence analysis
- **Export**: JSON and CSV results
- **Single Image**: Test individual images

### **Real-time Detection (`main.py`)**
- **Webcam**: Live emotion analysis
- **Performance**: 20-30 FPS on modern hardware
- **Features**: Temporal smoothing, confidence bars
- **UI**: FPS counter, processing time, controls
- **Controls**: Save frames, fullscreen, reset counters

## ğŸ§  Model Architecture

```
EfficientNet-B2 Backbone
â”œâ”€â”€ Pretrained ImageNet weights
â”œâ”€â”€ Advanced feature extraction
â””â”€â”€ Multi-scale feature maps

Custom Classifier
â”œâ”€â”€ AdaptiveAvgPool2d â†’ Flatten
â”œâ”€â”€ Dropout(0.4) â†’ Linear(1408â†’1024) â†’ BatchNorm â†’ ReLU
â”œâ”€â”€ Dropout(0.3) â†’ Linear(1024â†’512) â†’ BatchNorm â†’ ReLU
â”œâ”€â”€ Dropout(0.2) â†’ Linear(512â†’7)
â””â”€â”€ Softmax â†’ 7 emotion classes
```

## ğŸ“Š Training Configuration

| Parameter | Value | Description |
|-----------|-------|-------------|
| **Epochs** | 100 | Full training cycles |
| **Batch Size** | 32 | Images per batch |
| **Learning Rate** | 1e-3 | Initial learning rate |
| **Weight Decay** | 1e-4 | L2 regularization |
| **Optimizer** | AdamW | Advanced optimizer |
| **Scheduler** | OneCycleLR | Dynamic learning rate |
| **Loss** | CrossEntropyLoss | With label smoothing |

## ğŸ¨ Data Augmentation

### **Training Augmentations**
- **Geometric**: Random crop, flip, rotate, shift-scale-rotate
- **Blur**: Motion, median, Gaussian blur
- **Color**: CLAHE, brightness/contrast, hue/saturation
- **Noise**: Gaussian, ISO, multiplicative noise

### **Validation Transforms**
- **Resize**: 224Ã—224 pixels
- **Normalize**: ImageNet statistics
- **ToTensor**: PyTorch tensor conversion

## ğŸ“ˆ Expected Performance

| Metric | Target | Description |
|--------|--------|-------------|
| **Training Accuracy** | 85%+ | On training dataset |
| **Validation Accuracy** | 75%+ | On validation dataset |
| **Inference Speed** | 20-30 FPS | Real-time processing |
| **Model Size** | ~30MB | EfficientNet-B2 + classifier |

## ğŸ”§ Advanced Features

### **Temporal Smoothing**
- **History Buffer**: 5-frame emotion history
- **Consensus Voting**: Requires 2+ same emotion
- **Stable Predictions**: Reduces flickering

### **Performance Optimization**
- **Gradient Clipping**: Prevents exploding gradients
- **Mixed Precision**: Faster training (if supported)
- **Data Loading**: Multi-worker DataLoader
- **Memory Management**: Efficient batch processing

### **Training Monitoring**
- **Real-time Metrics**: Loss, accuracy, learning rate
- **Progress Bars**: TQDM integration
- **Checkpointing**: Save every 10 epochs
- **Best Model**: Auto-save highest accuracy

## ğŸ® Controls

### **Training Controls**
- **Keyboard Interrupt**: Save checkpoint and exit
- **Auto-save**: Best model and periodic checkpoints
- **Progress Display**: Real-time training metrics

### **Testing Controls**
- **Sample Limiting**: Control validation samples per class
- **Single Image**: Test individual images
- **Export Options**: JSON, CSV, visualizations

### **Runtime Controls**
- **'q'**: Quit detection
- **'s'**: Save current frame
- **'r'**: Reset counters
- **'f'**: Toggle fullscreen

## ğŸ“Š Evaluation Metrics

### **Classification Metrics**
- **Accuracy**: Overall correct predictions
- **Precision**: True positives / predicted positives
- **Recall**: True positives / actual positives
- **F1-Score**: Harmonic mean of precision and recall

### **Visualization Outputs**
- **Confusion Matrix**: Per-class prediction accuracy
- **Training History**: Loss and accuracy curves
- **Confidence Analysis**: Prediction confidence distribution
- **Performance Metrics**: Processing time and FPS

## ğŸš¨ Troubleshooting

### **Common Issues**

1. **CUDA Out of Memory**
   - Reduce batch size: `--batch_size 16`
   - Use CPU: Set `CUDA_VISIBLE_DEVICES=""`

2. **Low Training Accuracy**
   - Increase epochs: `--epochs 200`
   - Adjust learning rate: `--lr 5e-4`

3. **Overfitting**
   - Increase weight decay: `--weight_decay 1e-3`
   - Reduce model complexity

4. **Slow Training**
   - Reduce workers: Modify `num_workers` in code
   - Use smaller model: EfficientNet-B0

### **Performance Tips**

- **GPU**: Use CUDA for 3-5x speedup
- **Memory**: Close other applications
- **Storage**: Use SSD for faster data loading
- **Batch Size**: Optimize for your GPU memory

## ğŸ”® Future Enhancements

- [ ] **Multi-face Tracking**: Detect emotions for multiple people
- [ ] **Emotion History**: Track emotion changes over time
- [ ] **Real-time Statistics**: Live accuracy and confidence metrics
- [ ] **Export Results**: Save detection logs and statistics
- [ ] **Web Interface**: Browser-based emotion detection
- [ ] **Mobile Deployment**: Optimize for mobile devices
- [ ] **API Endpoints**: REST API for integration

## ğŸ“š Technical Details

### **Hardware Requirements**
- **Training**: 8GB+ RAM, GPU recommended
- **Inference**: 4GB+ RAM, any modern CPU/GPU
- **Storage**: 5GB+ for dataset and models

### **Software Dependencies**
- **Python**: 3.7+
- **PyTorch**: 1.9+
- **OpenCV**: 4.5+
- **Albumentations**: 1.1+

### **Dataset Information**
- **Source**: Kaggle FER2013
- **Size**: ~35,000 images
- **Classes**: 7 emotions
- **Format**: 48Ã—48 grayscale â†’ 224Ã—224 RGB

## ğŸ¤ Contributing

Feel free to:
- Report bugs and issues
- Suggest new features
- Improve documentation
- Optimize performance
- Add new emotion classes

## ğŸ“„ License

This project is for educational and research purposes. The trained model uses the FER2013 dataset.

---

## ğŸ‰ **Ready for Advanced Emotion Detection!**

**Start Training**: `python3 training.py --epochs 100`  
**Test Model**: `python3 test.py --max_samples 100`  
**Run Detection**: `python3 main.py`

Choose your path and achieve professional-grade emotion detection! ğŸš€
